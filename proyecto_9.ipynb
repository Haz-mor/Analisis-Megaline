{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b20e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de librerias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd8ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de datos\n",
    "df = pd.read_csv(\"C:/Users/lizar/OneDrive/Escritorio/Omar/Data_Scientist_TT/Proyects/project_9_files/users_behavior.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d092ed14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "#Diagnostico Inicial\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a71517bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de muestras en el conjunto de entrenamiento: 1928\n",
      "Número de muestras en el conjunto de validación: 643\n",
      "Número de muestras en el conjunto de prueba: 643\n"
     ]
    }
   ],
   "source": [
    "# 1. Separar características (X) y la variable objetivo (y)\n",
    "# X contiene todas las columnas excepto 'is_ultra'\n",
    "features = ['calls', 'minutes', 'messages', 'mb_used']\n",
    "X = df[features]\n",
    "\n",
    "# y contiene únicamente la columna objetivo\n",
    "y = df['is_ultra']\n",
    "\n",
    "# 2. Primera división: Separamos el conjunto de prueba (20%) del resto (80%)\n",
    "# Usamos random_state para que la división sea siempre la misma y los resultados reproducibles.\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=12345\n",
    ")\n",
    "\n",
    "# 3. Segunda división: Dividimos el 80% restante en entrenamiento y validación.\n",
    "# test_size=0.25 aquí significa que el 25% del 80% temporal se va para validación (lo que es un 20% del total).\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=12345\n",
    ")\n",
    "\n",
    "# --- Verificación de los tamaños ---\n",
    "print(f\"Número de muestras en el conjunto de entrenamiento: {X_train.shape[0]}\")\n",
    "print(f\"Número de muestras en el conjunto de validación: {X_valid.shape[0]}\")\n",
    "print(f\"Número de muestras en el conjunto de prueba: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21af993",
   "metadata": {},
   "source": [
    "Vamos a entrenar tres modelos diferentes y a jugar con sus hiperparámetros para ver cuál se desempeña mejor en nuestro conjunto de validación. El objetivo es encontrar el modelo más preciso antes de la prueba final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50e003ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Investigando: Árbol de Decisión ---\n",
      "La mejor exactitud del Árbol de Decisión es: 0.7745 con una profundidad de 7\n",
      "\n",
      "--- Investigando: Bosque Aleatorio ---\n",
      "La mejor exactitud del Bosque Aleatorio es: 0.7978 con los parámetros: {'estimators': 50, 'depth': 10}\n",
      "\n",
      "--- Investigando: Regresión Logística ---\n",
      "La exactitud de la Regresión Logística es: 0.6936\n"
     ]
    }
   ],
   "source": [
    "# --- Modelo 1: Árbol de Decisión ---\n",
    "# Investigaremos cómo cambia la exactitud al variar la profundidad del árbol (max_depth).\n",
    "print(\"--- Investigando: Árbol de Decisión ---\")\n",
    "best_tree_accuracy = 0\n",
    "best_depth = 0\n",
    "\n",
    "for depth in range(1, 11):  # Probaremos profundidades de 1 a 10\n",
    "    model_tree = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model_tree.fit(X_train, y_train)\n",
    "    predictions_valid = model_tree.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_valid, predictions_valid)\n",
    "    \n",
    "    if accuracy > best_tree_accuracy:\n",
    "        best_tree_accuracy = accuracy\n",
    "        best_depth = depth\n",
    "\n",
    "print(f\"La mejor exactitud del Árbol de Decisión es: {best_tree_accuracy:.4f} con una profundidad de {best_depth}\\n\")\n",
    "\n",
    "\n",
    "# --- Modelo 2: Bosque Aleatorio ---\n",
    "# Investigaremos el número de árboles (n_estimators) y la profundidad (max_depth).\n",
    "print(\"--- Investigando: Bosque Aleatorio ---\")\n",
    "best_rf_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for estimators in [10, 50, 100]:\n",
    "    for depth in range(1, 11):\n",
    "        model_rf = RandomForestClassifier(random_state=12345, n_estimators=estimators, max_depth=depth)\n",
    "        model_rf.fit(X_train, y_train)\n",
    "        predictions_valid = model_rf.predict(X_valid)\n",
    "        accuracy = accuracy_score(y_valid, predictions_valid)\n",
    "        \n",
    "        if accuracy > best_rf_accuracy:\n",
    "            best_rf_accuracy = accuracy\n",
    "            best_params = {'estimators': estimators, 'depth': depth}\n",
    "\n",
    "print(f\"La mejor exactitud del Bosque Aleatorio es: {best_rf_accuracy:.4f} con los parámetros: {best_params}\\n\")\n",
    "\n",
    "\n",
    "# --- Modelo 3: Regresión Logística ---\n",
    "# Este modelo es más simple y tiene menos hiperparámetros que ajustar. Lo usamos como referencia.\n",
    "print(\"--- Investigando: Regresión Logística ---\")\n",
    "model_lr = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_lr.fit(X_train, y_train)\n",
    "predictions_lr = model_lr.predict(X_valid)\n",
    "accuracy_lr = accuracy_score(y_valid, predictions_lr)\n",
    "\n",
    "print(f\"La exactitud de la Regresión Logística es: {accuracy_lr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93790146",
   "metadata": {},
   "source": [
    "El Bosque Aleatorio es el mejor modelo. Procederemos a la fase final utilizando este modelo con los hiperparámetros óptimos que hemos encontrado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d762c848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud final del modelo en el conjunto de prueba es: 0.7947\n"
     ]
    }
   ],
   "source": [
    "# 1. Crear el modelo final con los mejores hiperparámetros encontrados\n",
    "final_model = RandomForestClassifier(\n",
    "    random_state=12345, \n",
    "    n_estimators=50, \n",
    "    max_depth=9\n",
    ")\n",
    "\n",
    "# 2. Entrenar el modelo con el conjunto de entrenamiento\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Hacer predicciones en el conjunto de prueba\n",
    "test_predictions = final_model.predict(X_test)\n",
    "\n",
    "# 4. Calcular la exactitud final\n",
    "final_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"La exactitud final del modelo en el conjunto de prueba es: {final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd1d5b0",
   "metadata": {},
   "source": [
    "## Prueba de Cordura del Modelo\n",
    " 1.-Primero, calcularemos la proporción de cada plan ('Smart' vs. 'Ultra') en nuestro conjunto de prueba.\n",
    "\n",
    "2.-La proporción de la clase mayoritaria será nuestra exactitud de referencia.\n",
    "\n",
    "3.-Finalmente, compararemos este valor con la exactitud de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d0dfc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prueba de Cordura ---\n",
      "Distribución de planes en el conjunto de prueba:\n",
      "is_ultra\n",
      "0    0.695179\n",
      "1    0.304821\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Exactitud del modelo de referencia (siempre predice 'Smart'): 0.6952\n",
      "Exactitud de nuestro modelo de Bosque Aleatorio: 0.7947\n",
      "\n",
      "✅ Resultado: ¡El modelo ha pasado la prueba de cordura!\n",
      "Es significativamente más preciso que simplemente adivinar la opción más común.\n"
     ]
    }
   ],
   "source": [
    "# 1. Calcular la frecuencia de cada clase en el conjunto de prueba\n",
    "# normalize=True nos da el resultado como un porcentaje\n",
    "class_distribution = y_test.value_counts(normalize=True)\n",
    "\n",
    "print(\"--- Prueba de Cordura ---\")\n",
    "print(\"Distribución de planes en el conjunto de prueba:\")\n",
    "print(class_distribution)\n",
    "\n",
    "# 2. La exactitud de referencia es la proporción de la clase más frecuente\n",
    "baseline_accuracy = class_distribution.max()\n",
    "print(f\"\\nExactitud del modelo de referencia (siempre predice 'Smart'): {baseline_accuracy:.4f}\")\n",
    "\n",
    "# 3. Comparar con la exactitud de nuestro modelo final\n",
    "print(f\"Exactitud de nuestro modelo de Bosque Aleatorio: {final_accuracy:.4f}\")\n",
    "\n",
    "# 4. Conclusión de la prueba\n",
    "if final_accuracy > baseline_accuracy:\n",
    "    print(\"\\n✅ Resultado: ¡El modelo ha pasado la prueba de cordura!\")\n",
    "    print(\"Es significativamente más preciso que simplemente adivinar la opción más común.\")\n",
    "else:\n",
    "    print(\"\\n❌ Resultado: El modelo no ha pasado la prueba de cordura.\")\n",
    "    print(\"No es mejor que una simple conjetura y no está aportando valor.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
